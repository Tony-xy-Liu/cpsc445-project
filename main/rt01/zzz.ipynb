{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recovering & decompressing cached data from [{WORKSPACE}/main/rt01/cache/biocyc_org-ec.matrix.pkl.gz]\n",
      "[[ True  True  True ... False False False]\n",
      " [ True  True  True ... False False False]\n",
      " [ True  True  True ... False False False]\n",
      " ...\n",
      " [False  True False ... False False False]\n",
      " [ True  True  True ... False False False]\n",
      " [ True  True False ... False False False]]\n",
      "recovering & decompressing cached data from [{WORKSPACE}/main/rt01/cache/biocyc_ec.list.pkl.gz]\n",
      "['EC-2.7.1.2' 'EC-6.3.3.1' 'EC-3.5.2.9' ... 'EC-4.3.99.1' 'EC-1.13'\n",
      " 'EC-1.1.1.155']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path = list(set([\n",
    "    \"../../lib/\",\n",
    "] + sys.path))\n",
    "from local.caching import load, save, cache_fn_result\n",
    "\n",
    "mat = load ('biocyc_org-ec.matrix')\n",
    "print(mat)\n",
    "x = load('biocyc_ec.list')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_words():\n",
    "    return [[w for b, w in zip(row, x) if b] for row in mat]\n",
    "\n",
    "words = to_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomotopy as tp\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "swords = np.empty(shape=(len(words),), dtype=object)\n",
    "for i, row in enumerate(words):\n",
    "    swords[i] = row\n",
    "np.random.shuffle(swords)\n",
    "\n",
    "log_lls = []\n",
    "for k in [10, 100, 1000]:\n",
    "    kf = KFold(n_splits=5)\n",
    "    for train, test in kf.split(swords):\n",
    "        train, test = swords[train], swords[test]\n",
    "\n",
    "        mdl = tp.CTModel(k=k)\n",
    "        for word in train:\n",
    "            mdl.add_doc(word)\n",
    "        mdl.train(20)\n",
    "\n",
    "        docs = [mdl.make_doc(w) for w in test]\n",
    "        log_ll = np.mean(mdl.infer(docs)[1])\n",
    "        log_lls.append(log_ll)\n",
    "\n",
    "    np.random.shuffle(swords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "swords = np.empty(shape=(len(words),), dtype=object)\n",
    "for i, row in enumerate(words):\n",
    "    swords[i] = row\n",
    "np.random.shuffle(swords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5270.828421516478, -5218.981539988153, -5214.915713546574, -5250.457733654737, -5244.230967740531]\n",
      "-5239.882875289294\n"
     ]
    }
   ],
   "source": [
    "log_lls = []\n",
    "for k in [10]:\n",
    "    kf = KFold(n_splits=5)\n",
    "    for train, test in kf.split(swords):\n",
    "        train, test = swords[train], swords[test]\n",
    "\n",
    "        mdl = tp.CTModel(k=k)\n",
    "        for word in train:\n",
    "            mdl.add_doc(word)\n",
    "        mdl.train(100)\n",
    "\n",
    "        docs = [mdl.make_doc(w) for w in test]\n",
    "        log_ll = np.mean(mdl.infer(docs)[1])\n",
    "        log_lls.append(log_ll)\n",
    "\n",
    "    np.random.shuffle(swords)\n",
    "print(log_lls)\n",
    "print(np.mean(log_lls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "src/TopicModel/../Utils/TruncMultiNormal.hpp(56): wrong truncation range [0.652512, 0.652303]\n",
      "src/TopicModel/../Utils/TruncMultiNormal.hpp(56): wrong truncation range [1.38862, 1.3791]\n",
      "src/TopicModel/../Utils/TruncMultiNormal.hpp(56): wrong truncation range [0.346021, 0.343421]\n",
      "src/TopicModel/../Utils/TruncMultiNormal.hpp(56): wrong truncation range [1.50134, 1.49972]\n",
      "src/TopicModel/../Utils/TruncMultiNormal.hpp(56): wrong truncation range [0.954455, 0.951691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5349.577537935316, -5355.130382772743, -5416.364479972601, -5401.940052891136, -5452.99815790556]\n"
     ]
    }
   ],
   "source": [
    "log_lls = []\n",
    "for k in [100]:\n",
    "    kf = KFold(n_splits=5)\n",
    "    for train, test in kf.split(swords):\n",
    "        train, test = swords[train], swords[test]\n",
    "\n",
    "        mdl = tp.CTModel(k=k)\n",
    "        for word in train:\n",
    "            mdl.add_doc(word)\n",
    "        mdl.train(20)\n",
    "\n",
    "        docs = [mdl.make_doc(w) for w in test]\n",
    "        log_ll = np.mean(mdl.infer(docs)[1])\n",
    "        log_lls.append(log_ll)\n",
    "\n",
    "    np.random.shuffle(swords)\n",
    "print(log_lls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5395.202122295472"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 100\n",
    "np.mean(log_lls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5026.351116575882, -5028.145747488663, -5094.185628705754, -5081.300637324616, -5127.784921300973]\n",
      "-5071.5536102791775\n"
     ]
    }
   ],
   "source": [
    "log_lls = []\n",
    "for k in [20]:\n",
    "    kf = KFold(n_splits=5)\n",
    "    for train, test in kf.split(swords):\n",
    "        train, test = swords[train], swords[test]\n",
    "\n",
    "        mdl = tp.CTModel(k=k)\n",
    "        for word in train:\n",
    "            mdl.add_doc(word)\n",
    "        mdl.train(100)\n",
    "\n",
    "        docs = [mdl.make_doc(w) for w in test]\n",
    "        log_ll = np.mean(mdl.infer(docs)[1])\n",
    "        log_lls.append(log_ll)\n",
    "\n",
    "    np.random.shuffle(swords)\n",
    "print(log_lls)\n",
    "print(np.mean(log_lls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4970.1770649413165, -4940.973212937176, -4815.735794064299, -4921.162516965911, -4835.517063315509]\n",
      "-4896.713130444842\n"
     ]
    }
   ],
   "source": [
    "log_lls = []\n",
    "for k in [30]:\n",
    "    kf = KFold(n_splits=5)\n",
    "    for train, test in kf.split(swords):\n",
    "        train, test = swords[train], swords[test]\n",
    "\n",
    "        mdl = tp.CTModel(k=k)\n",
    "        for word in train:\n",
    "            mdl.add_doc(word)\n",
    "        mdl.train(100)\n",
    "\n",
    "        docs = [mdl.make_doc(w) for w in test]\n",
    "        log_ll = np.mean(mdl.infer(docs)[1])\n",
    "        log_lls.append(log_ll)\n",
    "\n",
    "    np.random.shuffle(swords)\n",
    "print(log_lls)\n",
    "print(np.mean(log_lls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "src/TopicModel/../Utils/TruncMultiNormal.hpp(56): wrong truncation range [0.960855, 0.960855]\n",
      "src/TopicModel/../Utils/TruncMultiNormal.hpp(56): wrong truncation range [-0.00288643, -0.00288658]\n",
      "src/TopicModel/../Utils/TruncMultiNormal.hpp(56): wrong truncation range [0.0329309, 0.0329303]\n",
      "src/TopicModel/../Utils/TruncMultiNormal.hpp(56): wrong truncation range [0.295589, 0.295589]\n",
      "src/TopicModel/../Utils/TruncMultiNormal.hpp(56): wrong truncation range [0.288807, 0.288807]\n",
      "src/TopicModel/../Utils/TruncMultiNormal.hpp(56): wrong truncation range [-0.0288584, -0.0290555]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4482.988982540987, -4520.909502515018, -4483.447292109683, -4554.173234992914, -4521.034317893791]\n",
      "-4512.510666010478\n"
     ]
    }
   ],
   "source": [
    "log_lls = []\n",
    "for k in [40]:\n",
    "    kf = KFold(n_splits=5)\n",
    "    for train, test in kf.split(swords):\n",
    "        train, test = swords[train], swords[test]\n",
    "\n",
    "        mdl = tp.CTModel(k=k)\n",
    "        for word in train:\n",
    "            mdl.add_doc(word)\n",
    "        mdl.train(100)\n",
    "\n",
    "        docs = [mdl.make_doc(w) for w in test]\n",
    "        log_ll = np.mean(mdl.infer(docs)[1])\n",
    "        log_lls.append(log_ll)\n",
    "\n",
    "    np.random.shuffle(swords)\n",
    "print(log_lls)\n",
    "print(np.mean(log_lls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "src/TopicModel/../Utils/TruncMultiNormal.hpp(56): wrong truncation range [2.20105, 2.19998]\n",
      "src/TopicModel/../Utils/TruncMultiNormal.hpp(56): wrong truncation range [0.281092, 0.281089]\n",
      "src/TopicModel/../Utils/TruncMultiNormal.hpp(56): wrong truncation range [0.0531093, -0.0181029]\n",
      "src/TopicModel/../Utils/TruncMultiNormal.hpp(56): wrong truncation range [0.0531093, 0.0501519]\n",
      "src/TopicModel/../Utils/TruncMultiNormal.hpp(56): wrong truncation range [-2.23336, -2.23336]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "log_lls = []\n",
    "for k in [50]:\n",
    "    kf = KFold(n_splits=5)\n",
    "    for train, test in kf.split(swords):\n",
    "        train, test = swords[train], swords[test]\n",
    "\n",
    "        mdl = tp.CTModel(k=k)\n",
    "        for word in train:\n",
    "            mdl.add_doc(word)\n",
    "        mdl.train(100)\n",
    "\n",
    "        docs = [mdl.make_doc(w) for w in test]\n",
    "        log_ll = np.mean(mdl.infer(docs)[1])\n",
    "        log_lls.append(log_ll)\n",
    "\n",
    "    np.random.shuffle(swords)\n",
    "print(log_lls)\n",
    "print(np.mean(log_lls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5302.475225603938, -5306.740798111498, -5370.406958283305, -5365.992406436324, -5416.354228239353]\n",
      "-5352.393923334884\n"
     ]
    }
   ],
   "source": [
    "log_lls = []\n",
    "for k in [50]:\n",
    "    kf = KFold(n_splits=5)\n",
    "    for train, test in kf.split(swords):\n",
    "        train, test = swords[train], swords[test]\n",
    "\n",
    "        mdl = tp.CTModel(k=k)\n",
    "        for word in train:\n",
    "            mdl.add_doc(word)\n",
    "        mdl.train(20)\n",
    "\n",
    "        docs = [mdl.make_doc(w) for w in test]\n",
    "        log_ll = np.mean(mdl.infer(docs)[1])\n",
    "        log_lls.append(log_ll)\n",
    "\n",
    "    np.random.shuffle(swords)\n",
    "print(log_lls)\n",
    "print(np.mean(log_lls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_10 = [-5270.828421516478, -5218.981539988153, -5214.915713546574, -5250.457733654737, -5244.230967740531]\n",
    "ll_20 = [-5026.351116575882, -5028.145747488663, -5094.185628705754, -5081.300637324616, -5127.784921300973]\n",
    "ll_30 = [-4970.1770649413165, -4940.973212937176, -4815.735794064299, -4921.162516965911, -4835.517063315509]\n",
    "ll_40 = [-4482.988982540987, -4520.909502515018, -4483.447292109683, -4554.173234992914, -4521.034317893791]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('EC-3.5.4.9', 0.004616112913936377), ('EC-2.8.1', 0.004211783409118652), ('EC-4.2.1.1', 0.0038007148541510105), ('EC-2.1.3.15', 0.003753543132916093), ('EC-6.1.1.18', 0.0036912087816745043), ('EC-3.8.1.11', 0.0035496936179697514), ('EC-2.1.1.182', 0.003485674737021327), ('EC-5.3.3.2', 0.003440187545493245), ('EC-2.3.1.61', 0.003404808696359396), ('EC-4.1.99.12', 0.0032683475874364376)]\n",
      "\n",
      "\n",
      "[('EC-2.5.1.15', 0.004352435003966093), ('EC-1.4.4.2', 0.004269869066774845), ('EC-2.7.1.23', 0.0038182823918759823), ('EC-3.5.4.25', 0.0035335132852196693), ('EC-2.1.3.2', 0.003472852287814021), ('EC-3.4.21', 0.0033987113274633884), ('EC-1.3.1.9', 0.0033919711131602526), ('EC-2.1.1.185', 0.003312774933874607), ('EC-6.3.2.17', 0.003295924747362733), ('EC-3.1.11.2', 0.0032605391461402178)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(2):\n",
    "    print(mdl.get_topic_words(topic_id=k))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7817"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mdl.get_topic_word_dist(topic_id=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('p445')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e298235de3f80241349a8694fdb95da545c99d9345677f7f41426565eea8c352"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
